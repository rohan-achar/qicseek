<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=windows-1252">
<META NAME="Generator" CONTENT="Microsoft Word 97">
<TITLE>lec15</TITLE>
</HEAD>
<BODY>

<U><FONT FACE="Geneva,Arial"><P>Lecture Fifteen--ICS 131--Win 2000--28 Feb 00</P>

<P>Review of Lecture Fourteen</P>
<DIR>
<DIR>
<DIR>

</U><P>�&#9;What are the problems?</P>
<P>�&#9;What are the security breaches?</P>

<P>�&#9;Who are the hackers?</P>

<P>�&#9;What can be done about computer security?</P>

<P>�&#9;What can you do on your PC?</P>

<P>�&#9;Any role for government?</P>
<U></DIR>
</DIR>
</DIR>

</U><P>-------------------------------------------------------------</P>

<U><P>Safety-critical applications</P>
</U>
<P>The Therac-25 Disaster</P>

<P>A computer based device for administering </P>
<P>radiation therapy to cancer victims.</P>

<P>Involved in six known accidents</P>
<P>three deaths directly attributable </P>
<P>to radiation overdoses</P>
<P> ---------------------------------------------------------------------</P>
<P><BR>
</P>

<P>Three flaws were identified:</P>

<P>1.  Poor interface design--</P><DIR>
<DIR>

<P>the machine could deliver a radiation dose</P>
<P>before the operator could change the dose </P>
<P>(e.g., lower it)</P>
</DIR>
</DIR>

<P>2.  Software failure--</P><DIR>
<DIR>

<P>safety checks bypassed whenever </P>
<P>a  6-bit program counter reached zero</P>
</DIR>
</DIR>

<P>3.  Software failure--</P><DIR>
<DIR>

<P>certain hardware safety interlocks</P>
<P>installed in an earlier version of the Therac</P>
<P>were replaced by software interlocks in the 25</P>
</DIR>
</DIR>

<P>---------------------------------------------------------</P>
<P>Complex systems are going to fail.</P>

<P>No such thing as a perfect system</P>

<P>-----------------------------------------------------------------</P>

<P>&nbsp;</P>
<P>Some definitions</P>

<P>A risk is a potential problem, with causes and effects.  </P>
<P>... avoiding risks is an exceedingly difficult task </P>
<P>that poses a pervasive problem.</P>

<P>Reliability implies that a systems </P>
<P>performs functionally as is expected,</P>
<P>and does so consistently over time</P>

<P>Security implies freedom from danger,</P>
<P>or more specifically, freedom from </P>
<P>undesirable events such as</P>
<P>malicious and accidental misuse.</P>

<P>Integrity implies that certain desirable </P>
<P>conditions are maintained over time.</P>

<P>--------------------------------------------------</P>
<P>Hardware, software, and people </P>
<P>are all sources of difficulties</P>
<P>Human safety and personal well-being </P>
<P>are of special concern.</P>

<P>--------------------------------------------------</P>
<P><BR>
</P>

<P>&nbsp;</P>
<P>What can be done?  A list of some things from JF and Neumann</P>

<P>1.  Testing and verification</P>

<P>2.  Duplex the hardware</P>

<P>3.  Software backups</P>

<P>4.  Software engineering</P>

<P>5.  Operator training</P>

<P>6.  Attitude</P>

<P>Pessimistic</P>
<P>Cautious</P>
<P>Near Misses--keeping track</P>
<P>Recording and reporting problems</P>
<P>------------------------------------------------------------</P>

<P>Techniques for Increasing Reliability</P><DIR>
<DIR>
<DIR>
<DIR>

<P>Fault tolerance</P>
<P>Forward error recovery</P>
<P>Backward error recovery</P></DIR>
</DIR>

<P>Error-Detecting and Error-Correcting Codes</P>
<P>Applicability and Limitations of Reliability Techniques</P>
<P>(table on p 231)</P>

<P>&nbsp;</P></DIR>
</DIR>

<P>Techniques of Software Development</P><DIR>
<DIR>

<P>System-Engineering and Software-Engineering Practice</P><DIR>
<DIR>

<P>Concept formation</P>
<P>Criteria for system evaluation</P>
<P>Requirements definition</P>
<P>System design</P>
<P>Object-oriented design</P>
<P>Consistency</P>
<P>Implementation</P>
<P>Correctness of Implementation</P>
<P>Evaluation</P>
<P>Management of development</P>
<P>Management of system build</P>
<P>System operations</P>
<P>System maintenance</P>
<P>Overview</P>

<P>&nbsp;</P></DIR>
</DIR>
</DIR>
</DIR>

<P>Neumann, Computer Related Risks</P>

<P>Chapter 9--Implications and Conclusions</P>

<P>9.1  Where to Place the Blame</P>

<P>"...[M]ost system problems are ultimately </P>
<P>and legitimately attributable to people.  </P>
<P>However, human failings are often blamed </P>
<P>on "the computer"--</P>
<P>perhaps to protect the individuals.  </P>

<P>&nbsp;</P>
<P>This attributionof blame seems to be </P>
<P>common in computers affecting consumers, </P>
<P>where human shortcomings are frequently </P>
<P>attributed to "a computer glitch."  </P>
<P>Computer system malfunctions are often due to</P>
<P>underlying causes attributable to people; </P>
<P>if the technology is faulty, the faults frequently </P>
<P>lie with people who create it and use it."</P>

<P>"Most accidents involving complex technology</P>
<P>are caused by a combination of</P>
<P>organizational,</P>
<P>managerial,</P>
<P>technical and, </P>
<P>sometimes sociological or political factors;</P>

<P>preventing accidents requires paying attention</P>
<P>to all the root causes,</P>
<P>not just the precipitating event </P>
<P>in a particular circumstance."</P>

<P>Leveson and Turner</P>

<P>-------------------------------------------------------------------------------</P>
<P>Littlewood and Strigini,  The Risks of Software, </P>
<P>Sci American, The Computer in the 21st Century,</P>
<P>1995</P>

<P>Formal proofs and</P>
<P>Fault tolerance</P>
<P>won't solve all of the problems</P>

<P>Three ways of coping with the problem</P>
<P>1.  non-quantifiable risks</P>
<P>2.  software not too critical</P>
<P>3.  accept limitations and live with them</P>

<P>&nbsp;</P>
<P>&nbsp;</P></FONT></BODY>
</HTML>

