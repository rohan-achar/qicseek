<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

	<head>
<meta http-equiv=Content-Type content="text/html; charset=iso-8859-1">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 11">
<meta name=Originator content="Microsoft Word 11">
<link rel=File-List href="NSFcareer_files/filelist.xml">
<link rel=Edit-Time-Data href="NSFcareer_files/editdata.mso">
<!--[if !mso]>
<style>
v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style>
<![endif]-->
<title>Max Welling NSF Career Page</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceName"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceType"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="City"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Welling</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor>Welling</o:LastAuthor>
  <o:Revision>6</o:Revision>
  <o:TotalTime>24</o:TotalTime>
  <o:Created>2004-11-16T16:18:00Z</o:Created>
  <o:LastSaved>2005-01-19T04:46:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>49</o:Words>
  <o:Characters>284</o:Characters>
  <o:Company> UCI</o:Company>
  <o:Lines>2</o:Lines>
  <o:Paragraphs>1</o:Paragraphs>
  <o:CharactersWithSpaces>332</o:CharactersWithSpaces>
  <o:Version>11.5606</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" LatentStyleCount="156">
 </w:LatentStyles>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Comic Sans MS";
	panose-1:3 15 7 2 3 3 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
a:link, span.MsoHyperlink
	{color:navy;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{color:maroon;
	text-decoration:underline;
	text-underline:single;}
p
	{mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
span.SpellE
	{mso-style-name:"";
	mso-spl-e:yes;}
@page Section1
	{size:8.5in 11.0in;
	margin:1.0in 1.25in 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-ansi-language:#0400;
	mso-fareast-language:#0400;
	mso-bidi-language:#0400;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="6146"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

	<body bgcolor=#fffede lang=EN-US link=navy vlink=maroon style="tab-interval:.5in" alink="#808000">
		<div class=Section1>
			<p class=MsoNormal>&nbsp;</p>
		</div>
		<div class=Section1 align="center">
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<p><span style='font-size:24.0pt;font-family:"Comic Sans MS"; color:red'><font color="#bf0000">Undirected Bipartite Graphical Models</font></span><span style='font-size:16.0pt;font-family:"Comic Sans MS"'><br>
					</span></p>
				<p><span style='font-size:16.0pt;font-family:"Comic Sans MS"'>with applications to Image Restoration and Information Retrieval.</span></p>
			</blockquote>
		</div>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<p></p>
			</blockquote>
		</div>
		<div class=Section1 align="center">
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<p><span style='font-size:16.0pt;font-family:"Comic Sans MS"'><font color="#0033bb"><span style="color:blue">Max Welling</span><br>
							<st1:PlaceType w:st="on"><span style="color:blue">University</span></st1:PlaceType><span style="color:blue"> of <st1:PlaceName w:st="on">California</st1:PlaceName> <st1:place w:st="on"><st1:City w:st="on">Irvine</st1:City></st1:place></span></font><span style="color:blue"><br style="mso-special-character:line-break">
						</span></span></p>
				<p><img src="NSF_logo.jpg" alt="" height="113" width="120" border="0"></p>
				<p><span style='font-family:"Comic Sans MS"'>This project is supported by an NSF Career Grant.<br>
					</span><span style='font-family:"Comic Sans MS"'>I&nbsp;like to personally thank NSF for supporting my research during the past 5 years. </span></p>
			</blockquote>
		</div>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<p></p>
									<hr>
									<p><font size="+2" face="Comic Sans MS">Introduction</font></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Max Welling</u> (2007)<br>
											<i style="mso-bidi-font-style:normal">Products of Experts<br>
											</i>ScholarPedia&nbsp;2007 [<a href="../publications/papers/PoE-SP.pdf">pdf</a>,<a href="http://www.scholarpedia.org/article/Product_of_Experts">url</a>]</b></p>
									<p>Most large scale data mining problems require efficient algorithms for processing, querying and storing information. It has been recognized that these algorithms need to be able to model uncertainty in our model assumptions and noise in the data. Probabilistic models and in particular graphical models are the ideal framework for these tasks, but also pose new computational challenges. Directed graphical models have been the dominant paradigm for many large scale data applications. However, properties inherent to the semantics of this class of models form an important hurdle for processing of queries and learning from data. The current approach to deal with this problem is to focus on approximate inference algorithms, which are often iterative and inefficient. In this manuscript we propose a new class of models, the ``undirected bipartite graphical'' (UBG) models, that largely avoids this computational barrier. Processing of queries is very fast while learning is achieved through a recently introduced technique called contrastive divergence.</p>
									<p></p>
									<hr>
									<p><font size="+2" face="Comic Sans MS">Project 1: </font><em><font size="+2" face="Comic Sans MS">Probablistic Models</font><font face="Comic Sans MS"> </font></em></p>
									<p><b><u><span style='mso-bidi-font-family:"Courier New"'>Max Welling, Michal Rosen-Zvi &amp; Geoffrey Hinton</span></u></b><b><span style='mso-bidi-font-family: "Courier New"'> (2004)</span></b><br>
										<b><i><span style='mso-bidi-font-family:"Courier New"'>Exponential Family Harmoniums with an Application to Information Retrieval<br>
												</span></i></b><b><span style='mso-bidi-font-family:"Courier New"'>NIPS 2004 [<a href="../publications/papers/GenHarm3.ps">ps</a> <a href="../publications/papers/GenHarm3.pdf">pdf</a>]</span></b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Peter Gehler, Alex Holub and Max Welling</u> (2006)<br>
											<i style="mso-bidi-font-style:normal">The Rate Adapting Poisson (RAP) model for Information Retrieval and Object Recognition.<br>
											</i>ICML 2006 [<a href="../publications/papers/rap_icml06_final.pdf">pdf</a>,<a href="http://www.kyb.tuebingen.mpg.de/bs/people/pgehler/rap/rap.html">software</a>]</b></p>
									<p>Directed models have become the dominant paradigm in machine learning. There are many good reasons this: they are easy to sample from, there is a nice (expectation maximization) framework to learn the parameters and it is even possible to search for optimal structure in a full Bayesian setting. Undirected models are much harder to handle, in particular because of the presence of a normalization constant (or partition function) that depends on the parameters and is usually intractable to compute.</p>
									<p>Harmoniums are two layer undirected graphical models (see picture below) where the top layer represents an array of hidden variables (or topic variables) while the bottom layer represents the observed random variables (e.g. the count values of words in documents). Effcient learning of parameter values is possible using the &quot;contrastive divergence algorithm&quot; (Hinton). This type of model has been particularly suitable for modeling of text data, where we (and others) have shown that classiffication and retrieval performance is better than for directed counterparts such as LDA (Blei,Ng,Jordan) . One particularly interesting feature that follows from the undirected nature of this model is that the process of inferring topic representations for documents is very fast (one bottom pass or equivalently one matrix multiplication) whereas directed models have to deal with issues like &quot;explaining away&quot; which makes approximate algorithms often the only way out.</p>
									<p></p>
									<p><img src="../research/RAP.gif" alt="" height="176" width="568" border="0" livesrc="../research/RAP.eps"></p>
									<p></p>
									<p><font color="#021f5e">Affiiliated people</font>:<br>
										Peter Gehler - PhD candidate, Max Planck institute in Tuebingen<br>
										Alex Holub - PhD candidate,Caltech<br>
										Geoffrey Hinton - professor univerity of Toronto<br>
										Michal Rosen Zvi - former postdoc UCI<br>
									</p>
									<p></p>
									<hr>
									<p></p>
									<p><font size="+2" face="Comic Sans MS">Project 2: <em>Image Denoising by Products of &quot;EdgePerts&quot;.</em> </font></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Peter Gehler and max Welling </u>(2005)</b><br>
										<b style="mso-bidi-font-weight:normal"><i style="mso-bidi-font-style:normal">Products of &ldquo;Edge-Perts&rdquo;</i></b><br>
										<b style="mso-bidi-font-weight:normal">NIPS 2005 [<a href="../publications/papers/NIPS-PoL2.pdf">pdf</a>] [<a href="http://www.kyb.mpg.de/bs/people/pgehler/index.htm">software</a>]</b></p>
									<p>One successful approach to image denoising is to 1) transform the image into the wavelet domain using a wavelet pyramid, 2) build a realistic probabilistic joint model of the wavelet coeffcients which captures their statistical dependencies, 3) use this model to see how the statistics of the observed (noisy) wavelet coefficients differs from what you expect from your model, 4) correct these discrepencies using a denoising algorithm (compute the maximum a posterior estimate of the clean wavelet coeffcients given your noisy estimates, assuming a known noise model) 5) invert the wavelet pyramid.</p>
									<p>In this project we have proposed a new model to describe the statistical regularities of wavelet coeffcients, based on the &quot;neural network&quot; shown below. Coeffcients get mapped to an energy, which serves as the (unnormalized) negative log-probability. As explained in our paper, this models accurately describes both the heavy tails of the marginal distributions as well as the &quot;bowtie&quot; dependencies between wavelet coefficients.</p>
									<p>As an additional feature, our denoiser will automatically pick the wavelet coeffcients which should be modelled jointly by one expert. We have shown that our results are competative with the current stat-of-the-art.</p>
									<p></p>
									<p></p>
									<p><a href="../research/NN.eps"><img src="../research/NN.gif" alt="" height="271" width="211" border="0" livesrc="../research/NN.eps"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../research/barbara_cropped_clean.gif" alt="" height="137" width="147" border="0" livesrc="../research/barbara_cropped_clean.eps">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../research/barbara_cropped_noisy.gif" alt="" height="139" width="136" border="0" livesrc="../research/barbara_cropped_noisy.eps">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../research/barbara_cropped_poedges.gif" alt="" height="140" width="147" border="0" livesrc="../research/barbara_cropped_poedges.eps"></p>
									<p></p>
									<p><font color="#021f5e">Affiiliated people</font>:<br>
										Peter Gehler - PhD candidate, Max Planck institute in Tuebingen<br>
									</p>
									<hr>
									<p><font size="+2" face="Comic Sans MS">Project 3: </font><em><font size="5" face="Comic Sans MS">Bayesian Inference and structure learning in undirected graphical models</font></em></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Sridevi Parise and Max Welling </u>(2005)<u><br>
											</u><i style="mso-bidi-font-style:normal">Learning in Markov Random Fields: An Empirical Study<br>
											</i>Joint Statistical Meeting JSM2005 [<a href="../publications/papers/MRFLearning.pdf">pdf</a>,<a href="software/software_BMRF/index.html">software</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Max Welling and Sridevi Parise</u> (2006)<br>
											<i style="mso-bidi-font-style:normal">Bayesian Random Fields: The Bethe-Laplace Approximation<br>
											</i>UAI 2006 [<a href="../publications/papers/LaplMRF_v6.pdf">pdf</a>]</b></p>
									<p><strong><u>Sridevi Parise and Max Welling</u> (2006)<br>
											<em>Bayesian Structure Scoring in Markov Random Fields</em><br>
											NIPS 2006 [<a href="../publications/papers/StructLearnMRF-submit.ps">ps</a>,<a href="../publications/papers/StructLearnMRF-submit.pdf">pdf</a>]</strong></p>
									<p>Learning the structure of a graphical model is very important to build good models. Where much progress has been made with infering structure for directed graphical models (i.e. Bayes' nets), there has been very little progress with undirected graphical models (MRFs) of which the &quot;unidrected bipartite graphical model&quot; is an instance. The reason for this is the presence of the normalization constant which depends on the parameters and which is intractable to compute.</p>
									<p>We propose to combine two approximations. First we use the assumption that the posterior is close to a Gaussian distribution. This makes a lot of sense for fully observed MRFs because the likelihood function is known to be convex in its parameters. The second approximation is based on an algorithm called &quot;linear response propagation&quot; to compute the covariance of this Gaussian. This approximation is in turn based on belief propagation. If we then finally approximate the log-partition function with the Bethe free energy (again belief propagation) and find good estimates for the &quot;maximum-a-posteriori&quot; (MAP) parameter values we are all set to go...</p>
									<p>Our main finding is that this approximation was indeed very accurate for fully observed MRFs and moreover orders of magnitude faster than sampling based methods. The bottleneck turns out to be a good estimate for the MAP&nbsp;parameter values. Performance is seen to crucially depend on this estimate. Next, we will look into models with hidden variables.</p>
									<p></p>
								</div>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</div>
		<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div class=Section1>
					<div class=Section1>
						<div class=Section1>
							<div class=Section1>
								<p><img src="exHist2_5k_small.jpg" alt="" height="322" width="446" border="0" livesrc="exHist2_5k.jpg"><br>
									Fit of estimates posterior distribution over parameter (red bars) compared to ground truth posterior (blue bars)</p>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</blockquote>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<p></p>
									<p><font color="#021f5e">Affiiliated people</font>:<br>
										Sridevi Parise - PhD candidate, UCI<br>
									</p>
									<p></p>
									<hr>
									<p><font size="+2" face="Comic Sans MS">Project 4: </font><em><font size="5" face="Comic Sans MS">Lifelong Learning with Nonparametric Bayesian Models<br>
											</font><font size="3" face="Comic Sans MS">(This project was not covered in the original career proposal but added after consent from the programme director in charge.) </font></em></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Ian Porteous, Alex Ihler, Padhriac Smyth and Max Welling</u> (2006)<br>
											<i style="mso-bidi-font-style:normal">Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick-Breaking Representation<br>
											</i>UAI 2006 [<a href="../publications/papers/ddp_uai06_v8.pdf">pdf</a>]</b></p>
									<p><strong><u>Yee Whye Teh, Dave Newman and Max Welling</u> (2006)<br>
											<em>A Collapsed Variational Bayesian Inference Algorithm for Latent Dirichlet Allocation</em><br>
											NIPS 2006 [<a href="../publications/papers/nips2006-colvar.ps">ps</a>,<a href="../publications/papers/nips2006-colvar.pdf">pdf</a>]</strong><br>
									</p>
									<p><strong><u>Kenichi Kurihara, Max Welling and Nikos Vlassis</u> (2006)<br>
											<em>Accelerated Variational DP mixture Models</em><br>
											NIPS 2006 [<a href="../publications/papers/vim_submit.ps">ps</a>,<a href="../publications/papers/vim_submit.pdf">pdf</a>]</strong></p>
									<p><strong><u>Kenichi Kurihara, Max Welling and Yee Whye Teh</u> (2007)<br>
											<em>Collapsed Variational Dirichlet Process Mixture Models</em><br>
											IJCAI 2007 [<a href="../publications/papers/cvdp-v6.ps">ps</a>,<a href="../publications/papers/cvdp-v6.pdf">pdf</a>]</strong></p>
									<p><strong><u>Yee Whye Teh, Kenichi Kurihara and Max Welling</u> (2007)<br>
											<em>Collapsed Variational Inference for HDP</em><br>
											NIPS 2007 [<a href="../publications/papers/CVHDP.pdf">pdf</a>]</strong></p>
									<p><strong><u>Max Welling, Ian Porteous and Evgeniy Bart</u> (2007)<br>
											<em>Infinite State Bayesian Networks For Structured Domains</em><br>
											NIPS 2007 [<a href="../publications/papers/ISBN-final.pdf">pdf</a>]</strong><br>
									</p>
									<p><strong><u>Dave Newman, Arthur Ascuncion, Padhriac Smyth and Max Welling</u> (2007)<br>
										</strong><strong><em>Distributed Inference for Latent Dirichlet Allocation</em></strong><strong><br>
											NIPS 2007 [<a href="../publications/papers/ParLDA.pdf">pdf</a>]</strong></p>
									<p><b style="mso-bidi-font-weight:normal"><u>A. Ascuncion, P. Smyth and M. Welling</u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Asynchronous Distributed Learning of Topic Models<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">NIPS</st1:place></st1:country-region> 2008 [<a href="../publications/papers/async_nips08.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>I. Porteous, A. Ascuncion, D. Newman, A. Ihler, P. Smyth and M. Welling</u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Fast Collapsed Gibbs Sampling For Latent Dirichlet Allocation<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">KDD</st1:place></st1:country-region> 2008 [<a href="../publications/papers/rtp378-porteous.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Max Welling, Y.W. Teh and B. Kappen</u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Hybrid Variational-MCMC Inference in Bayesian Networks<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">UAI</st1:place></st1:country-region> 2008 [<a href="../publications/papers/HybridVBMC-v6.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>R. Gomes, M. Welling and P. Perona</u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Memory Bounded Inference in Topic Models<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">ICML</st1:place></st1:country-region> 2008 [<a href="../publications/papers/MBHDP_ICML08-final-2.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Ian Porteous, Evgeniy Bart and Max Welling </u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Multi-HDP: A Nonparametric Bayesian Model for Tensor Factorization<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">AAAI</st1:place></st1:country-region> 2008 [<a href="../publications/papers/multihdpV10.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>Ryan Gomes, Max Welling and Pietro Perona</u>(2008)<u><br>
											</u><i style="mso-bidi-font-style:normal">Incremental Learning of Nonparametric Bayesian Mixture Models<br>
											</i><st1:country-region w:st="on"><st1:place w:st="on">CVPR</st1:place></st1:country-region> 2008 [<a href="../publications/papers/gomes_cvpr_08.pdf">pdf</a>]</b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>A. Asuncion, P. Smyth, M. Welling, Y.W. Teh </u>(2009)<br>
											<em>On Smoothing and Inference for Topic Models</em><br>
											UAI 2009 [<a href="../publications/papers/UAI_09.pdf">pdf]</a></b></p>
									<p><b style="mso-bidi-font-weight:normal"><u>D. Newman, A. Asuncion, P. Smyth, M. Welling </u>(2009)<br>
											<em>Distributed Algorithm for Topic Models</em><br>
											Journal Machine Learning Research 2009 [<a href="../publications/papers/distldajmlr.pdf">pdf</a>]</b></p>
									<p><strong><u>I. Porteous, A. Asuncion, M. Welling</u> (2010)<br>
											<em>Bayesian Matrix Factorization with Side Information and Dirichlet Process Mixtures</em><br>
											AAAI 2010 [<a href="../publications/papers/bpmfpp.pdf">pdf</a>]</strong></p>
									<p><strong><u>A. Asuncion, P. Smyth, M. Welling</u> (2010)<br>
											<em>Asynchronous Distributed Estimation of Topic Models for Document Analysis</em><br>
											Statistical Methodology 2010 [<a href="http://www.sciencedirect.com/science/article/pii/S1572312710000213">url</a>]<br>
										</strong></p>
									<p><strong><u>A. Asuncion, D. Newman, I. Porteous, S. Triglia, P. Smyth and M. Welling </u>(2010)<br>
											<em>Distributed Gibbs Sampling for Latent Variable Models</em><br>
											Bookchapter in: Scaling Up Machine Learning, Cambridge University Press</strong></p>
									<p><strong><u>D. Gorur, L. Boyles and M. Welling </u>(2011)<br>
											<em>Scalable Inference on Kingman&rsquo;s Coalescent using Pair Similarity</em><br>
											AISTATS 2012 [<a href="../publications/papers/fastCoalescentAISTATS_2012.pdf">pdf</a>]<br>
										</strong></p>
									<p><strong><u>M. Welling, I. Porteous and K. Kurihara</u> (2012)<br>
											<em>Exchangeable Inconsistent Priors for Bayesian Posterior Inference</em><br>
											Workshop on Information Theory and Applications (ITA) 2012 [<a href="../publications/papers/FlexPriors_ITA12.pdf">pdf</a>]</strong></p>
									<p>Data generated by society is doubling every year. Google has currently more images stored than any single human will see in a lifetime (in the order of 1 billion images assuming we process approximately one image per second). Big science projects such as the Large Hadron Collider (LHC), the Large Synoptic Survey Telescope (LSST) and the Low Frequency Array (LOFAR) will generate in the order of 10 peta-bytes of data each year (1 peta-byte is the equivalent of 1 billion books of text). Industry and government agencies collect large quantities of data in the form of hyperlink clicking patterns, purchasing behaviour, credit histories, surveillance camera video, and so on. Multimedia applications such as cell-phones and digital cameras will acquire new data (and store it at websites such as Flickr and YouTube) at an unprecedented scale.</p>
								</div>
							</div>
						</div>
					</div>
				</div>
				<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
					<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
						
					</blockquote>
				</blockquote>
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<p>Modern datasets are dynamic, i.e. continuously changing. The tools of traditional statistics, which are mainly concerned with static datasets of fixed size, are no longer adequate. Instead we need statistical machinery that can handle &quot;open ended&quot; streams of information. This necessitates novel learning paradigms that adapt the complexity of the statistical model in response to the amount of structure available in the data. A model that is too simple will not capture all predictive structure in the data while a model that is too complex will have over-fitted to noise (or unpredictive &quot;structure&quot;) in the data. Moreover, unlike most of today's learning algorithms, this new class of algorithms should learn as long as it is in operation, a property which we will refer to as &quot;lifelong learning&quot;.</p>
									<p>As a motivating biological example, consider a young child: At birth s/he will only recognize very simple object categories (such as mommies face), but this representation will quickly grow more complex as more of the world is observed. It is estimated that by the age of two years a child has learned 10,000 different object categories which implies approximately 5 new categories every day on average. This representation of the visual world changes as long as we live.</p>
									<p>How will we respond to this data deluge? It presents an opportunity as well as a challenge on the plate of the computer scientist. Promising new developments in this respect is &ldquo;grid computing&rdquo; and &ldquo;cloud computing&rdquo;. Already, Amazon is allowing anyone to log into their network of servers called &ldquo;Elastic Cloud Computing&rdquo; and run processes on thousands of CPUs in parallel. The computing power of grid networks can only be exploited if algorithms use their parallel architecture. It follows that algorithms have to operate in a distributed fashion: analyze data locally and exchange or combine partial results.</p>
									<p>This project has started the ambitious goal of developing algorithms that can handle very large streams of data. Inference algorithms are based on variational approximations or collapsed Gibbs sampling. The algorithms can perform inference distributed over many machines allowing them to scale to billions of tokens. Moreover, the algorithms can grow in response to newly discovered structure in the data and process information in an online fashion. The essential ingredient that allows this feature is the nonparametric Bayesian modeling paradigm. Combining this statistical tool with Bayesian networks and fast inference has led us to develop the <em>infinite state Bayesian network </em>(ISBN). See the figure below for an example. In this model, variables are related to other variables through the usual dependency structure of Bayesian networks, but have a potentially infinite number of hidden states available to model the structure of the data (not all of these states are &quot;alive&quot;).</p>
									<p><img src="InfiniteStateBayesianNetworkv2.jpg" alt="" height="278" width="351" border="0" livesrc="Infinite%20State%20Bayesian%20Network%20v2.jpg">      <img src="Taxonomy.jpg" alt="" height="280" width="454" border="0"><br>
										<br>
										Infinite State Bayesian Network</p>
									<p><font color="#021f5e">Affiiliated people</font>:<br>
										Ian Porteous - PhD&nbsp;candidate at UCI<br>
										Arthur Acuncion - PhD&nbsp;candidate at UCI<br>
										Kenichi Kurihara - Former PhD Student at Tokyo Institute of Technology<br>
										Yee Whye Teh - Reader at University College London<br>
										Dave Newman - Project Scientist at UCI<br>
										Ryan Gomes - PhD candidate at Caltech<br>
										Padhriac Smyth - Professor at UCI<br>
										Alex Ihler - Assistant Professor at UCI<br>
										Pietro Perona - Professor at Caltech<br>
										Nikos Vlassis - Assistant Professor at University Crete<br>
										Evgeniy Bart - Former Postdoc<br>
										Dilan Gorur<br>
										Levi Boyles<br>
									</p>
									<p></p>
									<div>
										<hr>
										<p></p>
										<p><font size="+2" face="Comic Sans MS">Project 5:<em> </em></font><em><font size="+2" face="Comic Sans MS">eXtreme Components Analaysis (XCA)</font><font face="Comic Sans MS"> </font></em></p>
										<p></p>
										<p><b><u><span style='mso-bidi-font-family:"Courier New"'>Max Welling, Felix Agakov &amp; Chris Williams</span></u></b><b><span style='mso-bidi-font-family: "Courier New"'> (2003)</span></b><br>
											<b><i><span style='mso-bidi-font-family:"Courier New"'>Extreme Components Analysis</span></i></b><br>
											<b><span style='mso-bidi-font-family:"Courier New"'>NIPS 2003 [<a href="../publications/papers/XCA5.pdf">pdf</a>]</span></b></p>
										<p></p>
										<p>XCA is a statistical technique that extends PCA (principal component analysis) and MCA (minor components analysis) into one probabilistic model. The XCA algorithm extracts the optimal combination of principal and minor components to fit the data. In addition it formulates a probabilistic model based on these components. The XCA algorithm is based on a single eigenvalue decomposition of the data-covariance matrix.</p>
										<p>Estimating minor components is difficult from a statistical perspective. The reason is that minor components are prone to overfitting: due to sample fluctuations there are bound to be directions with very low variance. We have recently extended this technique to a Bayesian variant which provides a principled regularization of the minor components. We can show that the Bayesian XCA model only picks minor components when they are really present in the data.</p>
										<p>In a dataset of landmark points on the wing of a mosquito (see figure below) we found as minor components directions which changed the landmark positions that attached to the mosquito's body. Clearly this is represents real evolutionary constraint.</p>
										<p></p>
										<p></p>
										<p><img src="mosquito_wing.jpg" alt="" height="176" width="501" border="0" livesrc="../../latex/Bayesian%20XCA/BayesXCA/SIAM%20BayesXCA%20(copy)/mosquito_wing.eps"></p>
										<p></p>
										<p><font color="#021f5e">Affiiliated people</font>:<br>
											Felix Agakov<br>
											Chris Williams<br>
											Yutian Chen</p>
										<p></p>
										<hr>
										<p></p>
										<p><font size="+2" face="Comic Sans MS">Project 6: </font><em><font size="+2" face="Comic Sans MS">Bayesian Kmeans<br>
												</font></em></p>
										<p></p>
										<p><b style="mso-bidi-font-weight:normal"><u>Kenichi Kurihara and Max Welling </u>(2008)<u><br>
												</u><i style="mso-bidi-font-style:normal">Bayesian K-Means as a &ldquo;Maximization-Expectation&rdquo; Algorithm<br>
												</i><st1:country-region w:st="on"><st1:place w:st="on">Neural Computation, Neural Computation 21(4), pp.1-28 [<a href="../publications/papers/BKM_NC_v7.pdf">pdf</a>]</st1:place></st1:country-region></b></p>
										<p><b style="mso-bidi-font-weight:normal"><u>Max Welling and Kenichi Kurihara </u>(2005)<u><br>
												</u><i style="mso-bidi-font-style:normal">Bayesian K-Means as a &ldquo;Maximization-Expectation&rdquo; Algorithm<br>
												</i><st1:country-region w:st="on"><st1:place w:st="on">SIAM</st1:place></st1:country-region> Conference on Data Mining SDM2006 [<a href="../publications/papers/BKMSiam06-short-v2.pdf">pdf</a>,<a href="../publications/papers/BKM_techrep.pdf">tech-report</a>,<a href="http://mi.cs.titech.ac.jp/kurihara/bkm.html">software</a>]</b></p>
										<p></p>
										<p>The Expectation Maximization algorithm (EM) is a well known tool to find the maximum likelihood parameters settings for a probabilistic model with hidden variables. Bayesian extentions exist that iterate between estimating distribution sover hidden variables and distributions over parameters. This is the variational Bayesian framework. Under certain circumstances it is more efficient to treat the hidden variables as point estimates instead of full distributions.</p>
										<p>We developed this idea under the name &quot;Maximization Expectation&quot; algorithm (ME). It still has the advantage of a full Bayesian treatment in the sense that overly complex models are being penalized. This provides a level of protection against overfitting. On the other hand, the point estimates for the states of the hidden variables allow for fast datastructures to speed up learning.</p>
										<p>As an example we considered Bayesian K-means where we still maximize over cluster assignments but treat the parameters such as the cluster means, variances and mixture weights in a Bayesian manner. KD trees are then used to speed up learning which makes Bayesian clustering with millions of datapoints feasible. As a bonus, one can estimate the number of clusters necessary to model the data well.</p>
										<p>In the figure below we show how this philosophy fits into the general scheme of algorithms already known.</p>
										<p></p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</div>
		<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div class=Section1>
					<div class=Section1>
						<div class=Section1>
							<div class=Section1>
								<p><img src="algorithms2.jpg" alt="" height="192" width="426" border="0" livesrc="../../latex/bkm/figures/algorithms2.eps"></p>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</blockquote>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<div>
										<p></p>
										<p></p>
										<p><font color="#021f5e">Affiiliated people</font>:<br>
											Kenichi Kurihara<br>
										</p>
										<p></p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</div>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<div>
										<hr>
										<p></p>
										<p><font size="+2" face="Comic Sans MS">Project 6: <em>Learning with Dynamic Weights</em></font></p>
										<p><strong><u>M. Welling </u>(2009)<br>
												<em>Herding Dynamic Weights to Learn</em><br>
												ICML 2009 [<a href="../publications/papers/herding_icml09_final.pdf">pdf</a>]</strong></p>
										<p><strong><u>M. Welling </u>(2009)<br>
												<em>Herding Dynamic Weights for Partially Observed Random Field Models</em><br>
												UAI 2009 [<a href="../publications/papers/HerdingRBM-final.pdf">pdf</a>]</strong></p>
										<p><strong><u>Y. Chen and M. Welling </u>(2010)<br>
												<em>Parametric Herding</em><br>
												AISTATS 2010 [<a href="../publications/papers/AIstats2010.pdf">pdf</a>]</strong></p>
										<p><b><u>M. Welling and Y. Chen </u>(2010)<br>
												<em>Statistical Inference Using Weak Chaos and Infinite Memory</em><br>
												Proceedings of the Int'l Workshop on Statistical-Mechanical Informatics<br>
												(IW-SMI 2010)[<a href="../publications/papers/HerdingKyoto2010-submit.pdf">pdf</a>]</b></p>
										<p><b><u>Y. Chen, M. Welling and A. Smola </u>(2010)<br>
												<em>Supersamples from Kernel-Herding</em><br>
												UAI 2010 [<a href="../publications/papers/UAI2010.pdf">pdf</a>]</b></p>
										<p><b><u>A. Gelfand, L. Van Der Maaten, Y. Chen, M. Welling </u>(2010)<br>
												<em>On Herding and the Perceptron Cycling Theorem</em><br>
												NIPS 2010 [<a href="../publications/papers/CH-v17-2.pdf">pdf</a>]</b></p>
										<p><b><u>Y. Chen, A. Gelfand, C. Fowlkes and M. Welling </u>(2011)<br>
												<em>Integrating Local Classifiers through Nonlinear Dynamics on Label Graphs with an Application to Image Segmentation</em><br>
												ICCV 2011 <a href="../publications/papers/HerdingCRFImSeg_v9_camera_ready.pdf">[pdf</a>] </b></p>
										<hr align="left" size="1" width="33%">
										</p>
										<div id="ftn1">
											<p>Learning a Markov random field is difficult due to a number of problems:</p>
											<p>1. To compute the gradient of the log-likelihood one needs to compute sufficient statistics under the model. These are intractable.</p>
											<p>2. In the presence of hidden variables, the log-likelihood is highly non-convex as a function of the parameters, leading to many local minima in which learning can (and will) get stuck.</p>
											<p>3. Convergence to the optimal ML&nbsp;parameter is slow (linear) for almost any algorithm that is used in practice.</p>
											<p>4. Even given a model, sampling states from it is difficult because the sampler might get stuck in local minima is state space.</p>
											<p>These considerations have led me to define a deterministic dynamical system that performs learning and sampling in one go. The major advantage is that the system mixes very fast between what one would expect are reasonable modes of a distribution (see figure below where successive samples of the digit 4 are shown). The disadvantage is that it is hard to assess what the inductive bias represents. One thing can be proved, namely that the average sufficient statisics which hold at the maximum likelihood solution for the corresponding MRF&nbsp;problem still hold for the samples of herding. However, the entropy away from those constraints is likely not maximal.</p>
											<p>Intriguingly, the set of allowed weights often has fractal dimension (zero Lebesque measure). One can also show that the entropy production of this dynamical system is polynomial, (instead of exponential for stochastic and fully chaotic systems) consistent with what is known in the literature as &quot;weak chaos&quot; or &quot;pseudochaos&quot;. We are currently exploring whether we can formulate a generalized maximum entropy principle. We are also interested in what design features make herding work and if we can define deep herding systems with many layers of neurons.</p>
											<p></p>
											<p></p>
											<p><img src="Tipi5.jpg" alt="" height="305" width="366" border="0"> <img src="Sampled-4.jpg" alt="" height="304" width="319" border="0"></p>
											<div class=Section1>
												<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
													<div>
														<div>
															<div>
																<div>
																	<div class=MsoNormal>
																		<div></div>
																	</div>
																</div>
															</div>
														</div>
													</div>
												</blockquote>
											</div>
											<p><font color="#021f5e">Affiiliated people</font>:<br>
												Yutian Chen<br>
												Andrew Gelfand<br>
												Laurens van der Maaten<br>
											</p>
											<hr>
											<p></p>
											<p><font size="+2" face="Comic Sans MS">Project 7: </font><em><font size="5" face="Comic Sans MS">Dynamical Product Models for Financial Time Series</font></em></p>
											<p><strong><u>Y. Chen and M. Welling </u>(2010)<br>
													Dynamical Products of Experts for Modeling Financial Time Series<br>
													ICML 2010 [<a href="../publications/papers/DPoTicmlsubmission-3.pdf">pdf</a>]</strong></p>
											<p>We describe a dynamical model based on the hierarchical Product of Student-t distribution to model volatility of stocks. This model is similar to GARCH type models in that they can describe the persistence of volatility over time which is a form of higher order dependency between the variances of two consecutive random variables. But unlike GARCH models, the dependencies are stochastic and not deterministic. The model can also be considered as ICA over time. We show improved performance in predicting &quot;Value at Risk&quot;.</p>
											<p><img src="GraphicalModelDPoT.jpg" alt="" height="264" width="367" border="0"></p>
											<p></p>
											<p><font color="#021f5e">Affiiliated people</font>:<br>
												Yutian Chen<br>
												<br>
											</p>
											<hr>
											<p><font size="+2" face="Comic Sans MS">Project 8: </font><em><font size="5" face="Comic Sans MS">Statistical Optimization</font></em></p>
											<p><strong><u>A. Korattikara, L. Boyles, J. Kim, H. Park and M. Welling</u> (2011)<br>
													<em>Statistical Optimization for Nonnegative Matrix Factorization</em><br>
													AISTATS 2011 [<a href="../publications/papers/FASTNMF_AISTATS2011.pdf">pdf</a>] </strong></p>
											<p><strong><u>L. Boyles, A. Korattikara, D. Ramanan and M. Welling</u> (2011)<br>
													<em>Statistical Tests for Optimization Efficiency</em><br>
													NIPS 2011 [<a href="../publications/papers/NIPS2011_STATEST_v1.pdf">pdf</a>][<a href="http://www.ics.uci.edu/%7elboyles/">software</a>]</strong></p>
											<p>Machine learning is often presented as choosing a loss function and minimizing that loss on some dataset (hopefully resulting in some convex optimization problem). This view is limiting in the sense that statistical optimization problems are not ordinary optimization problems due to the random nature of the data. In this frequentist view of the world we may imagine sampling a few other datasets and observing how our loss function fluctuates due to this resampling. One of  the consequences of these simple observations is of course that we can overfit. In other words, the scale of the fluctuations in the optimal parameters due to resampling the dataset is the scale of precision to which we should fit the parameters. Methods such as bagging leverage this idea.<br>
												<br>
												What is much less exploited is the fact these observations also allow one to perform optimization of the loss function much more efficiently. In particular, during the initial stages of learning, every datapoint will carry roughly the same information on how to improve a parameter. Thus, when the model is still bad, there is a lot of redundancy in the data in terms of how to change the model. As a result we only need to query a few data items to get a good idea of  how to update the model. We exploit this idea by performing hypothesis tests before every update to inform us how many data-points to use for our updates. More precisely, if the probability of making an error in the update direction of more than 90 degrees is too large we will recruit more datapoints in our batch in order to increase our precision. Moreover, when we can not pass these tests even when we have recuited all the data in our dataset, we should stop updating altogether. This has lead to a highly effcient learning algorithm with a principled stopping criterion that unlike methods such as stochastic gradient descent have basically no hyperparameters to tune (except for an interpretable threshold of how large the probability of updating in the wrong direction is tolerated). </p>
											<p><img src="splash.jpg" alt="" height="307" width="295" border="0"></p>
											<p>
											</p>
											<p><font color="#021f5e">Affiiliated people</font>:<br>
												Levi Boyles<br>
												Anoop Koratikkara<br>
												Deva Ramanan<br>
												<br>
											</p>
											<p></p>
											<hr>
											<p><font size="+2" face="Comic Sans MS">Project 9: </font><em><font size="5" face="Comic Sans MS">Stochastic Gradient Bayesian Posterior Sampling</font></em></p>
											<p><strong><u>M. Welling and Y.W. Teh</u> (2011)<br>
													<em>Bayesian Learning via Stochastic Gradient Langevin Dynamics</em><br>
													ICML 2011 <a href="../publications/papers/stoclangevin_v6.pdf">[pdf]</a> </strong></p>
											<p>Frequentist methods such as stochastic gradient descent or statistical optimization (see project 8 above) are very efficient at quickly finding good predictive models. Their main trick is to realize that we do not need to use all the data to improve the model parameters. In fact for models far from optimality we can use few data items and large stepsizes to improve our models and then either decrease our stepsize (SGD) or increase our batchsize (SO) to increase the resolution of the updates as we get closer to the optimal solution. </p>
											<p>In contrast, Bayesian MCMC methods that sample from the posterior distribution are hopelessly ineffcient in this respect. For example, a single accept/reject step will have to inspect all the data-items twice. Clearly, because burn-in is often nothing more than a stochastic version of optimization this is a huge waste of  computational resources. But we argue that even when the sampler has reached the high probablity regions we can trade-off a little bit of  approximation error (bias) for large computational wins that can pay back in terms of faster mixing and reduction of error due to variance. In fact, when we have only a fixed amount of time to reduce our error, this bias is often completely masked by sampling variance during the relevant time interval that we allow ourselves to run our samplers.</p>
											<p>We have developed new samplers that leverage this trade-off. The stochastic gradient Langevin sampler starts of with basically being a stochastic gradient ascent optimizer. But since we add noise to the gradients, at a certain point the noise we add is going to dominate the noise that we create due to subsampling the data, and the sampler automatically turns into a Langevin posterior sampler. By adding the approapriate preconditioner we can also make sure that for large stepsizes (and thus fast mixing) the sampler draws from the optimal Gaussian approximation of the posterior (as given by the &quot;Bayesian Central Limit Theorem&quot;). </p>
											<p>I believe that it is time to start thinking about approximate Bayesian posterior sampling and the inherent trade-offs that come from the fact that we only have a limited amount of time to learn our models and make predictions. </p>
											<p><img src="lr_scatter_2x2.gif" alt="" height="266" width="342" border="0" livesrc="lr_scatter_2x2.jpg">                <img src="atuc_rerr_mn_xt200.gif" alt="" height="271" width="356" border="0" livesrc="atuc_rerr_mn_xt200.jpg"></p>
										</div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</blockquote>
		</div>
		<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
					<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
						<div id="ftn1" class=Section1>
							<div id="ftn1" class=Section1>
								<div id="ftn1" class=Section1>
									<div id="ftn1" class=Section1>
										<div id="ftn1" class=Section1>
											
										</div>
									</div>
								</div>
							</div>
						</div>
					</blockquote>
				</blockquote>
			</blockquote>
		</blockquote>
		<div class=Section1>
			<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
				<div>
					<div>
						<div>
							<div>
								<div class=MsoNormal>
									<div>
										<div id="ftn1">
											<p><font color="#021f5e">Affiiliated people</font>:<br>
												Yee Whye Teh<br>
												Sungjin Ahn<br>
												Anoop Korattikara<br>
											</p>
											<p><br>
											</p>
											<hr>
											<div class=Section1>
												<blockquote style="margin-top:5.0pt;margin-bottom:5.0pt">
													<div>
														<div>
															<div>
																<div>
																	<p></p>
																</div>
															</div>
														</div>
													</div>
												</blockquote>
											</div>
										</div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
				<p><span style="font-family:Arial">[<a href="http://www.ics.uci.edu/~welling/index.html">Back to Max <span class=SpellE>Welling's's</span> home page</a>]&nbsp;</span></p>
			</blockquote>
		</div>
	</body>

</html>

